{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdflib import Graph, RDF, Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge files\n",
    "df1 = pd.read_csv('https://raw.githubusercontent.com/nih-cfde/ReproToxTables/main/Susceptibility%20Scores%20and%20GWAS%20Gene%20Lists/GWAS%20Phenotype%20Gene/Text%20Mining-GWAS-CNS%20Disease%20Phenotype%20Gene%20Associations.csv')\n",
    "df2 = pd.read_csv('https://raw.githubusercontent.com/nih-cfde/ReproToxTables/main/Susceptibility%20Scores%20and%20GWAS%20Gene%20Lists/GWAS%20Phenotype%20Gene/Text%20Mining-GWAS-Great%20Vessels%20Disease%20Phenotype%20Gene%20Associations.csv')\n",
    "df3 = pd.read_csv('https://raw.githubusercontent.com/nih-cfde/ReproToxTables/main/Susceptibility%20Scores%20and%20GWAS%20Gene%20Lists/GWAS%20Phenotype%20Gene/Text%20Mining-GWAS-Heart%20Disease%20Phenotype%20Gene%20Associations.csv')\n",
    "df_c = pd.concat([df1, df2, df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.concat([df1, df2, df3])\n",
    "df_c['HPO Term'] = df_c['HPO Term'].str.capitalize()\n",
    "df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HP to disease mapping\n",
    "df_dis = df_c[['HPO Term', 'HPO Accession']].drop_duplicates().to_csv('hpo_mappings.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate genes by a disease\n",
    "df_c = df_c[['HPO Term', 'Gene Symbol']].groupby(['HPO Term']).agg({'Gene Symbol': '\\t'.join})\n",
    "df_c.reset_index(inplace=True)\n",
    "df_c['HPO Term'] = df_c['HPO Term'].str.capitalize()\n",
    "df_c.to_csv('Text_Mining_GWAS.gmt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge hpo_mappings.tsv into defects_hpo_mappings.tsv and de-duplicate manually \n",
    "defects_map = pd.read_csv('defects_hpo_mappings.tsv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph()\n",
    "\n",
    "disease = Namespace(\"https://www.orpha.net/ORDO/\")\n",
    "phenotype = Namespace(\"https://purl.obolibrary.org/obo/\")\n",
    "relationship = Namespace(\"https://semanticscience.org/resource/\")\n",
    "gene_symbol = Namespace(\"https://identifiers.org/hgnc.symbol/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.bind('gene_symbol', gene_symbol)\n",
    "g.bind('disease', disease)\n",
    "g.bind('relationship', relationship)\n",
    "g.bind('phenotype', phenotype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Text_Mining_GWAS.gmt', 'r') as f: \n",
    "    for l in f.readlines(): \n",
    "        p = l.split('\\t')[0].strip()\n",
    "        hp_id = defects_map.loc[p, 'hp']\n",
    "        if hp_id.startswith('ORPHA'):\n",
    "            hp_id = hp_id.replace(':', '_').replace('ORPHA', 'Orphanet')\n",
    "            g.add((disease[hp_id], RDF.type, relationship['SIO_010299']))\n",
    "            for gene in l.split('\\t')[2:]:\n",
    "                g.add((disease[hp_id], relationship['SIO_000983'], gene_symbol[gene]))\n",
    "        else:\n",
    "            hp_id = hp_id.replace(':', '_')\n",
    "            g.add((phenotype[hp_id], RDF.type, relationship['SIO_010056']))\n",
    "            for gene in l.split('\\t')[2:]:\n",
    "                g.add((phenotype[hp_id], relationship['SIO_000983'], gene_symbol[gene.strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.serialize(format=\"turtle\", destination=\"Text_Mining_GWAS.ttl\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c82f5b6c528626954ea994dc81ee747853d56d7563ac30240837c45bbb6f5e6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
